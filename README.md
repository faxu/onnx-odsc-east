## Accelerate ML model inferencing using open-source tools and deploy the model

In this workshop, we'll convert BERT model from PyTorch to the interoperable ONNX format, then inference the converted model using the open-source ONNX Runtime. We'll then demonstrate how to deploy the ONNX model as a hosted webservice using Azure Machine Learning.
